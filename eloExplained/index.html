<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>How Elo Works</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: 1;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../blog.css" />
  <link rel="stylesheet" href="../code/bootstrap.min.css">
  <script src="../code/jquery.min.js"></script>
  <script src="../code/bootstrap.min.js"></script>

  <ul class="bar">
    <li class="barli"><a class="active" href="/">Home</a></li>
    <li class="barli"><a href="/sportsMaths/">Triathlon Mathematics</a></li>
  </ul>

  <script src="../code/tex-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">How Elo Works</h1>
</header>
<section id="introduction" class="container">
<h1>Introduction</h1>
<p>The wikipedia page describes ELO as</p>
<p><code>The Elo[a] rating system is a method for calculating the relative skill levels of players in zero-sum games such as chess. It is named after its creator Arpad Elo, a Hungarian-American physics professor.</code></p>
<p>If you google how ELO works, you are usually presented with the
following two equations</p>
<p><span class="math display">\[ P(A \text{ beats } B) =
\frac{10^{R_A/400}}{10^{R_A/400} + 10^{R_B/400}}\]</span></p>
<p>where <span class="math inline">\(R_A\)</span> and <span
class="math inline">\(R_B\)</span> are the ELO ratings of player A and
player B and <span class="math inline">\(P(A \text{ beats } B)\)</span>
is the probability that A beats B. Once player A actually plays player
B, we get one of the following realisations:</p>
<ul>
<li>A wins : <span class="math inline">\(X=1\)</span></li>
<li>A loses : <span class="math inline">\(X=0\)</span></li>
<li>Draw : <span class="math inline">\(X=0.5\)</span></li>
</ul>
<p>Once this game is finished A‚Äôs ratings are updated using the
formula</p>
<p><span class="math display">\[ R_{new} = R_{old} + \Big(X - P(A \text{
beats } B)\Big)*K\]</span> where K is usually 32.</p>
<h2 id="worked-out-example">Worked out example</h2>
<p>Taken from <a
href="https://www.youtube.com/watch?v=VnOVLBbYlU0">talk</a></p>
<p><img src="pngs/example.png" alt="drawing" width="400"/></p>
<p>Shown above is an example of two players with ELO ratings 1500 and
1900 and how their scores would change if they played against each
other.</p>
<p>One may verify these equations from Mark Glickmans detailed <a
href="http://www.glicko.net/research/acjpaper.pdf">survey</a> of chess
rankings. If one were to read the entire survey, then one would learn
that Arpad Elo assumed that player A‚Äôs score came from a Gaussian
Distribution with mean <span class="math inline">\(R_A\)</span> and a
constant variance for all players. Thus the the probability above is
just the probability of A drawing a bigger number than B. However, if
you have ever seen the normal distribution, it is not clear why the
above equation is true. Where is the <span
class="math inline">\(400\)</span> coming from? Why is the exponent in
base 10 - the pdf of the normal distribution has no sign of a base 10?
It took me a while to work out how this formula comes out to be true.
Gary A. Mamon‚Äôs <a
href="http://www2.iap.fr/users/gam/ratings.pdf">document</a> was very
useful. This post is the complete derivation of where the above formula
comes from. <strong>Spoiler alert:</strong> Contary to what <a
href="https://www.youtube.com/watch?v=VnOVLBbYlU0">conference talks</a>
and many other youtube <a
href="https://www.youtube.com/watch?v=AsYfbmp0To0&amp;vl=en-GB">explanations</a>
tell you, the above formula is <strong>NOT</strong> exactly the
probability of one normal random variable being bigger than the other.
In fact it is a close approximation to the first order approximation of
the actual probability of two gaussian variables differing. Futhermore
the approximation is only good when the two players are relatively
equal.</p>
<h2 id="what-is-elo-colloquially">What is ELO colloquially</h2>
<p>This probability <a
href="https://math.stackexchange.com/questions/1731991/why-does-the-elo-rating-system-work">forum</a>
does a good job at what equation 1 means.</p>
<p><code>The key point about the Elo rating is that it is related to the log-odds of players winning games. It assumes that there is a relationship across players, so that (ignoring the possibility of draws) if Player B is 10 times as likely to beat Player A as Player A is to be beat Player ùêµ, and Player C is 10 times as likely to beat Player B as Player B is to beat Player C, then Player C is 100 times as likely to beat Player A as Player A is to beat Player C.  The Elo rating is scaled so that (ignoring the possibility of draws) if Player B is 10 times as likely to beat Player A as Player A is to beat Player B then the Elo rating of Player B should be 400 higher than the Elo rating of Player A. Combining this with the earlier assumption has the result that, if Player C is 100 times as likely to beat Player A as Player A is to beat Player C, then the Elo rating of Player C should be 800 higher than the Elo rating of Player A: each linear increase in the difference of Elo ratings of 400 multiplies the odds of the better player winning by a factor of 10, so this is a logarithmic relationship.</code></p>
<p>The author of the post works the math out. The above exerpt is the
following equation which is the same as our equation 1.</p>
<p><span class="math display">\[ 400\log_{10}\Big( \frac{ P(A \text{
beats } B)}{ P(B \text{ beats } A)} \Big) = R_A - R_B\]</span></p>
<p>As <span class="math inline">\(P(A \text{ beats } B) = 1 - P(B \text{
beats } A)\)</span>, if you re-arrange the above equation the math works
out.</p>
<p>But this is <span class="math inline">\(NOT\)</span> how Arpad Elo
described his system.</p>
<h2 id="what-did-arpad-elo-actually-say">What did Arpad Elo actually
say?</h2>
<p>In his original work, <a
href="https://hughchristensen.com/papers/academic_papers/glickman1998b.pdf">cited
in</a> Elo claimed that player x‚Äôs ability came from a normal
distribution with mean <span class="math inline">\(R_x\)</span> and
constant standard deviation <span
class="math inline">\(\sigma=200\)</span>. So if player A and player B
met for a chess match. The outcome of the game could be modelled as the
two of them drawing a number from their individual gaussian
distributions. The one with the higher number wins. One could view the
figure below as the rating distribution of 3 different players. A key
assumption made was that all players have the same variance i.e.¬†all
players are equally consistent.</p>
<p><img src="pngs/normals.png" alt="drawing" width="400"/></p>
<p>Under, this setting, What is the probability that <span
class="math inline">\(A\)</span> beats <span
class="math inline">\(B\)</span>?</p>
<p><span class="math display">\[\begin{align*}
P(A \text{ beats } B) &amp;= P(a &gt; b) \\
&amp;= P(a - b &gt; 0)
\end{align*}\]</span></p>
<p>where <span class="math inline">\(a \sim Normal(R_A,
\sigma^2)\)</span> and <span class="math inline">\(b \sim Normal(R_B,
\sigma^2)\)</span>. The two players simply draw a number form their
distrubutions, the bigger number is the winner. A useful property of
gaussian random variables with different means <span
class="math inline">\(R_A\)</span> and <span
class="math inline">\(R_B\)</span> and same variance <span
class="math inline">\(\sigma^2\)</span>, is that their difference is
also a gaussian random variable with mean <span
class="math inline">\(\Delta = R_A - R_B\)</span> and variance <span
class="math inline">\(2\sigma^2\)</span>. See for a <a
href="https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables">proof</a>.
Let <span class="math inline">\(\delta = a - b\)</span>, and let <span
class="math inline">\(x = P(A \text{ beats } B)\)</span></p>
<p><span class="math display">\[\begin{align*}
P(A \text{ beats } B) &amp;= P(\delta &gt; 0) \\
x &amp;= \int_{0}^{\infty} \frac{1}{2\sigma\sqrt{\pi}}e^{-\Big(
\frac{\delta - \Delta}{2\sigma}\Big)^2}d\delta \\
&amp;= \frac{1}{2}\Big[ 1 + e.r.f(\frac{2\Delta}{2\sigma})\Big]
\end{align*}\]</span></p>
<p>where e.r.f is the <a
href="https://en.wikipedia.org/wiki/Error_function">error function</a>.
The last line is just using the CDF of a normal distribution, Solving
for <span class="math inline">\(\Delta\)</span>, we get</p>
<p><span class="math display">\[ \Delta = 2\sigma (erf)^{-1}[2x
-1]\]</span> where <span class="math inline">\((erf)^{-1}\)</span> is
the <a
href="https://en.wikipedia.org/wiki/Error_function#Inverse_functions">inverse</a>
of the error function. Plugging in <span
class="math inline">\(\sigma=200\)</span> we get</p>
<p><span class="math display">\[ \Delta = 400(erf)^{-1}[2x -1]\]</span>
Ok now we have a 400 but there is still no base 10 or beautiful closed
form expression that everyone claims to exist. Let us denote the
difference in ELO rating obtained from equation 1, as <span
class="math inline">\(\Delta_{log} = R_B - R_A\)</span>. We had</p>
<p><span class="math display">\[ \Delta_{log} =
400\log_{10}(\frac{x}{1-x})\]</span> where <span class="math inline">\(x
= P(A \text{
beats } B)\)</span> as defined before.</p>
<p>What we are interested in knowing is how are <span
class="math inline">\(\Delta_{log}\)</span> and <span
class="math inline">\(\Delta\)</span> related. In chess players that
play each other are mostly on the same skill level. So let us Consider
what happens when players A and B are quite close to each other i.e
<span class="math inline">\(\delta \approx 0\)</span> and <span
class="math inline">\(x \approx 1/2\)</span>.</p>
<p>To understand this, we use Taylor Series (MacLaurin) expansions
centered at <span class="math inline">\(\delta=0\)</span> of <span
class="math inline">\(erf^{-1}\)</span>.</p>
<p><span class="math display">\[\begin{align*}
erf^{-1}(z) &amp;= \sum_{k=0}^{\infty}
\frac{c_k}{2k+1}\Big(\frac{\sqrt{\pi}}{2}z\Big)^{2k+1} \\
&amp;= \frac{1}{2}\sqrt{\pi}\Big( z + \frac{\pi}{12}z^3 + ... \Big) \\
\end{align*}\]</span></p>
<p>where c0 = 1 and <span class="math inline">\(c_k = \sum_{m=0}^{k-1}
\frac{c_mc_{k-1-m}}{(m+1)(2m+1)}\)</span>. Substituting <span
class="math inline">\(z = 2x -1\)</span> in the above equation and
taking the first order exansion we get</p>
<p><span class="math display">\[\Delta = 400\sqrt{\pi}(x -
\frac{1}{2})\]</span></p>
<p>The Taylor expansion of <span class="math inline">\(f(x) =
ln(\frac{x}{1-x})\)</span> centered at 1/2 is the following:</p>
<p><span class="math display">\[\begin{align*}
\Delta_{log} &amp;= 400\log_{10}(\frac{x}{1-x})\\
&amp;=  \frac{400}{ln(10)}\sum_{n=0}^{\infty}\frac{f^{(n)}(a)}{n!}(x-a)^n
\\
\end{align*}\]</span></p>
<p>The first order approximation is</p>
<p><span class="math display">\[ \Delta_{log} = \frac{1600}{ln(10)}(x -
\frac{1}{2})\]</span></p>
<p>Now we have two very similar looking equations</p>
<p><span class="math display">\[ \Delta_{log} = \frac{1600}{ln(10)}(x -
\frac{1}{2})\]</span></p>
<p><span class="math display">\[\Delta = 400\sqrt{\pi}(x -
\frac{1}{2})\]</span></p>
<p><span class="math inline">\(\Delta_{log} - \Delta = (x -
\frac{1}{2})(709.0 - 694.9)\)</span>. There‚Äôs only a 2% difference when
the players are closely matched. However when players are not nearly
equal if we were to plot <span
class="math inline">\(\Delta_{log}\)</span> and <span
class="math inline">\(\Delta\)</span> the differences are grater than
10%. This is why its important in chess to have evenly matched players
play against each other. A 2% difference accounts to 268 points on ELO
scale. This is also why the equation used in practice is a decent
approximation of what Elo suggested. However it is <strong>NOT</strong>
the probability that one normal random variable is bigger than the
other.</p>
</section>
<div id="footer">
   All models are wrong, but some are useful
</div>
</body>
</html>
